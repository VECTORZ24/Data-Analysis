{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "103b92eb-c7fd-495f-90e9-75cc19a3d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this script we will create star schema tables (fact table and dimensional tables) of the dataset\n",
    "#we will save the tables data to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ff28dd36-c97f-4a6c-8103-5fa36024128d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122073, 22)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will concatenate the 3 slices of the cleaned data\n",
    "import pandas as pd\n",
    "data1=pd.read_csv('Amazon-Sale-Report-0.csv')\n",
    "data2=pd.read_csv('Amazon-Sale-Report-1.csv')\n",
    "data3=pd.read_csv('Amazon-Sale-Report-2.csv')\n",
    "cleaned_data=pd.concat([data1,data2,data3])\n",
    "cleaned_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "23a09040-8129-4cea-a953-545f831e5f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing foreign keys per column:\n",
      " date_id          0\n",
      "product_id       0\n",
      "location_id      0\n",
      "fulfilment_id    0\n",
      "dtype: int64\n",
      "Rows assigned to UNKNOWN location_id=0: 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FULL STAR SCHEMA BUILD (dims + fact) - IDEMPOTENT VERSION\n",
    "# - Safe to run multiple times\n",
    "# - Fixes *_x/*_y merge collisions\n",
    "# ============================================================\n",
    "\n",
    "# 0) Start from a clean copy of the ORIGINAL cleaned_data\n",
    "df = cleaned_data.copy()\n",
    "\n",
    "# If you previously ran other scripts, remove any old keys to avoid collisions\n",
    "for col in [\"product_id\", \"date_id\", \"fulfilment_id\", \"loc_id\", \"location_id\"]:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(columns=[col])\n",
    "\n",
    "# 1) Parse Date\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\").dt.normalize()\n",
    "\n",
    "# 2) Robust cleanup for location columns\n",
    "loc_cols = [\"ship-postal-code\", \"ship-state\", \"ship-city\"]\n",
    "for c in loc_cols:\n",
    "    df[c] = df[c].astype(str).str.strip().str.upper()\n",
    "\n",
    "df[loc_cols] = df[loc_cols].replace({\"NAN\": pd.NA, \"NONE\": pd.NA, \"NULL\": pd.NA, \"\": pd.NA})\n",
    "df[\"ship-postal-code\"] = df[\"ship-postal-code\"].str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "\n",
    "# 3) Normalize SKU (for product mapping)\n",
    "df[\"SKU\"] = df[\"SKU\"].astype(str).str.strip().str.upper()\n",
    "df[\"SKU\"] = df[\"SKU\"].replace({\"NAN\": pd.NA, \"NONE\": pd.NA, \"NULL\": pd.NA, \"\": pd.NA})\n",
    "\n",
    "# 4) Normalize fulfilment attributes\n",
    "ful_cols = [\"Fulfilment\", \"Sales_Channel\", \"ship-service-level\", \"Courier_Status\", \"B2B\"]\n",
    "for c in ful_cols:\n",
    "    df[c] = df[c].astype(str).str.strip().str.upper()\n",
    "\n",
    "df[ful_cols] = df[ful_cols].replace({\"NAN\": pd.NA, \"NONE\": pd.NA, \"NULL\": pd.NA, \"\": pd.NA})\n",
    "\n",
    "# ============================================================\n",
    "# DIMENSIONS\n",
    "# ============================================================\n",
    "\n",
    "# dim_product (grain = SKU)\n",
    "dim_product = (\n",
    "    df[[\"SKU\", \"Style\", \"Category\", \"Size\", \"ASIN\"]]\n",
    "    .dropna(subset=[\"SKU\"])\n",
    "    .drop_duplicates(subset=[\"SKU\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "dim_product[\"product_id\"] = range(1, len(dim_product) + 1)\n",
    "dim_product = dim_product[[\"product_id\", \"SKU\", \"Style\", \"Category\", \"Size\", \"ASIN\"]]\n",
    "\n",
    "# dim_location (grain = postal+state+city)\n",
    "dim_location = (\n",
    "    df[[\"ship-postal-code\", \"ship-state\", \"ship-city\"]]\n",
    "    .dropna(subset=loc_cols)\n",
    "    .drop_duplicates(subset=loc_cols)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "dim_location[\"loc_id\"] = range(1, len(dim_location) + 1)\n",
    "dim_location = dim_location[[\"loc_id\", \"ship-state\", \"ship-city\", \"ship-postal-code\"]]\n",
    "\n",
    "# Add Unknown location row (so FK is never null)\n",
    "unknown_loc = pd.DataFrame([{\n",
    "    \"loc_id\": 0,\n",
    "    \"ship-state\": \"UNKNOWN\",\n",
    "    \"ship-city\": \"UNKNOWN\",\n",
    "    \"ship-postal-code\": \"UNKNOWN\"\n",
    "}])\n",
    "dim_location = pd.concat([unknown_loc, dim_location], ignore_index=True)\n",
    "\n",
    "# dim_date (grain = Date)\n",
    "dim_date = (\n",
    "    df[[\"Date\"]]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\"Date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "dim_date[\"date_id\"] = range(1, len(dim_date) + 1)\n",
    "dim_date[\"day\"] = dim_date[\"Date\"].dt.day\n",
    "dim_date[\"month\"] = dim_date[\"Date\"].dt.month\n",
    "dim_date[\"year\"] = dim_date[\"Date\"].dt.year\n",
    "dim_date = dim_date[[\"date_id\", \"Date\", \"day\", \"month\", \"year\"]]\n",
    "\n",
    "# dim_fulfilment (grain = unique fulfilment combo)\n",
    "dim_fulfilment = (\n",
    "    df[ful_cols]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "dim_fulfilment[\"fulfilment_id\"] = range(1, len(dim_fulfilment) + 1)\n",
    "dim_fulfilment = dim_fulfilment[[\"fulfilment_id\"] + ful_cols]\n",
    "\n",
    "# ============================================================\n",
    "# MAP KEYS BACK INTO df (merges)\n",
    "# ============================================================\n",
    "\n",
    "# product_id\n",
    "df = df.merge(dim_product[[\"SKU\", \"product_id\"]], on=\"SKU\", how=\"left\")\n",
    "\n",
    "# date_id\n",
    "df = df.merge(dim_date[[\"Date\", \"date_id\"]], on=\"Date\", how=\"left\")\n",
    "\n",
    "# fulfilment_id\n",
    "df = df.merge(dim_fulfilment[ful_cols + [\"fulfilment_id\"]], on=ful_cols, how=\"left\")\n",
    "\n",
    "# loc_id (merge by full location keys)\n",
    "df = df.merge(\n",
    "    dim_location[[\"ship-postal-code\", \"ship-state\", \"ship-city\", \"loc_id\"]],\n",
    "    on=[\"ship-postal-code\", \"ship-state\", \"ship-city\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "df[\"loc_id\"] = df[\"loc_id\"].fillna(0).astype(int)\n",
    "\n",
    "# ============================================================\n",
    "# FACT TABLE\n",
    "# ============================================================\n",
    "fact_orders = (\n",
    "    df[[\"Order_ID\", \"date_id\", \"product_id\", \"loc_id\", \"fulfilment_id\", \"Qty\", \"Amount\"]]\n",
    "    .rename(columns={\n",
    "        \"Order_ID\": \"order_id\",\n",
    "        \"loc_id\": \"location_id\",\n",
    "        \"Qty\": \"qty\",\n",
    "        \"Amount\": \"amount\"\n",
    "    })\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# VALIDATION\n",
    "# ============================================================\n",
    "missing_fk = fact_orders[[\"date_id\", \"product_id\", \"location_id\", \"fulfilment_id\"]].isna().sum()\n",
    "print(\"Missing foreign keys per column:\\n\", missing_fk)\n",
    "\n",
    "unknown_count = (fact_orders[\"location_id\"] == 0).sum()\n",
    "print(f\"Rows assigned to UNKNOWN location_id=0: {unknown_count}\")\n",
    "\n",
    "# Now you have: dim_product, dim_location, dim_date, dim_fulfilment, fact_orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "13a944dd-e309-475b-8bc3-46108cbee3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving tables to csv files\n",
    "dim_product.to_csv(\"dim_product.csv\", index=False)\n",
    "dim_location.to_csv(\"dim_location.csv\", index=False)\n",
    "dim_date.to_csv(\"dim_date.csv\", index=False)\n",
    "dim_fulfilment.to_csv(\"dim_fulfilment.csv\", index=False)\n",
    "\n",
    "# ---- Fact table ----\n",
    "fact_orders.to_csv(\"fact_orders.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ca6e6-1bcf-4e99-b754-c83154648214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
